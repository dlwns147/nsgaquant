{
    "fp16": {
        "tps": {
            "1.128.128": 49.463762938078276
        },
        "peak_memory": {
            "1.128.128": 14.5834641456604
        },
        "gemm": {
            "1.128.128": 34.81397270203861
        },
        "gemv": {
            "1.128.128": 50.16938453248926
        },
        "ttft": {
            "1.128.128": 30.205031391233206
        }
    },
    "2bit": {
        "tps": {
            "1.128.128": 80.64926653120385
        },
        "peak_memory": {
            "1.128.128": 4.599440097808838
        },
        "gemm": {
            "1.128.128": 6.088827554876682
        },
        "ttft": {
            "1.128.128": 165.78919789753854
        }
    },
    "3bit": {
        "tps": {
            "1.128.128": 68.68918363829938
        },
        "peak_memory": {
            "1.128.128": 5.593565464019775
        },
        "gemm": {
            "1.128.128": 2.4529103117806272
        },
        "ttft": {
            "1.128.128": 409.26625952124596
        }
    },
    "4bit": {
        "tps": {
            "1.128.128": 79.74077818045663
        },
        "peak_memory": {
            "1.128.128": 6.154341220855713
        },
        "gemm": {
            "1.128.128": 5.920490346601446
        },
        "ttft": {
            "1.128.128": 170.39846605621278
        }
    },
    "args": {
        "model_name_or_path": "meta-llama/Llama-2-7b-hf",
        "use_ft": true,
        "use_owq": false,
        "backend_2bit": "gptq",
        "backend_3bit": "gptq",
        "backend_4bit": "gptq",
        "batch_size": 1,
        "seq_length": 128,
        "gen_length": 128,
        "file_name": "nsgaquant_benchmark_speed_128.json"
    },
    "unit": {
        "tps": "tokens/second",
        "gemm": "tokens/second",
        "gemv": "tokens/second",
        "ttft": "latency(s)",
        "peak_memory": "GB"
    }
}